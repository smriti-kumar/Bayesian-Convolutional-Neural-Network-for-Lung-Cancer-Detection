{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#google drive mount to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DaA3P405IWfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#library imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfpl = tfp.layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8fQg6fyMyMOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image size and paths\n",
        "#ct scans dataset - https://drive.google.com/drive/folders/1nxOu5vIfjI7VpHf5tdmdybElWHNbQMXn?usp=sharing\n",
        "#pathology images dataset - https://drive.google.com/drive/folders/1yqR6SJg6JYIVUGNDdqZFcgeeS-GXzSbO?usp=sharing\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "ct_train_path = '/content/drive/MyDrive/lung_cancer_ct_scans_dataset/train'\n",
        "ct_test_path = '/content/drive/MyDrive/lung_cancer_ct_scans_dataset/test'\n",
        "path_train_path = '/content/drive/MyDrive/lung_cancer_path_dataset/train'\n",
        "path_test_path = '/content/drive/MyDrive/lung_cancer_path_dataset/test'"
      ],
      "metadata": {
        "id": "POpwgW2tyPJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define transformations for images\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "nB-7ae7w0ZcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and test sets for ct and pathology images\n",
        "ct_training_set = train_datagen.flow_from_directory(ct_train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "ct_test_set = test_datagen.flow_from_directory(ct_test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "path_training_set = train_datagen.flow_from_directory(path_train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "path_test_set = test_datagen.flow_from_directory(path_test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "IjMUEZip0bT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multimodal data generator\n",
        "def multimodal_generator(ct_generator, path_generator):\n",
        "    while True:\n",
        "        ct_images, ct_labels = ct_generator.next()\n",
        "        path_images, path_labels = path_generator.next()\n",
        "        yield [ct_images, path_images], ct_labels"
      ],
      "metadata": {
        "id": "v4jYCIBwjEwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bayesian convolutional layers\n",
        "class BayesianConv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, activation=tf.nn.relu, **kwargs):\n",
        "        super(BayesianConv2D, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel_posterior = self.add_weight(\n",
        "            name='kernel_posterior',\n",
        "            shape=(self.kernel_size[0], self.kernel_size[1], input_shape[-1], self.filters),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bias_posterior = self.add_weight(\n",
        "            name='bias_posterior',\n",
        "            shape=(self.filters,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.nn.conv2d(inputs, self.kernel_posterior, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        output = tf.nn.bias_add(output, self.bias_posterior)\n",
        "        return self.activation(output)"
      ],
      "metadata": {
        "id": "a3TK4YtJF5-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bayesian dense layers\n",
        "class BayesianDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=tf.nn.relu, **kwargs):\n",
        "        super(BayesianDense, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel_posterior = self.add_weight(\n",
        "            name='kernel_posterior',\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bias_posterior = self.add_weight(\n",
        "            name='bias_posterior',\n",
        "            shape=(self.units,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.matmul(inputs, self.kernel_posterior)\n",
        "        output = tf.nn.bias_add(output, self.bias_posterior)\n",
        "        return self.activation(output)"
      ],
      "metadata": {
        "id": "nifGnYxF2rPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multimodal architecture\n",
        "def create_multimodal_bcnn(input_shape):\n",
        "    #ct scan path\n",
        "    input1 = Input(shape=input_shape)\n",
        "    x1 = BayesianConv2D(32, (3, 3))(input1)\n",
        "    x1 = MaxPooling2D((2, 2))(x1)\n",
        "    x1 = BayesianConv2D(64, (3, 3))(x1)\n",
        "    x1 = MaxPooling2D((2, 2))(x1)\n",
        "\n",
        "    #pathology images path\n",
        "    input2 = Input(shape=input_shape)\n",
        "    x2 = BayesianConv2D(32, (3, 3))(input2)\n",
        "    x2 = MaxPooling2D((2, 2))(x2)\n",
        "    x2 = BayesianConv2D(64, (3, 3))(x2)\n",
        "    x2 = MaxPooling2D((2, 2))(x2)\n",
        "\n",
        "    merged = Concatenate()([x1, x2])\n",
        "    flattened = Flatten()(merged)\n",
        "\n",
        "    x = BayesianDense(128)(flattened)\n",
        "    x = BayesianDense(64)(x)\n",
        "\n",
        "    output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[input1, input2], outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "-l7z8BLt2uE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model = create_multimodal_bcnn(input_shape=(224, 224, 3))\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_x4L70C72weC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kFi7pwmBhSB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "history = model.fit(\n",
        "    multimodal_generator(ct_training_set, path_training_set),\n",
        "    steps_per_epoch=len(ct_training_set),\n",
        "    epochs=50,\n",
        "    validation_data=multimodal_generator(ct_test_set, path_test_set),\n",
        "    validation_steps=len(ct_test_set),\n",
        ")"
      ],
      "metadata": {
        "id": "va7QZtLO0gFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot accuracy and loss over epochs\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "GPpdr5QT0h06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy\n",
        "test_loss, test_acc = model.evaluate(multimodal_generator(ct_test_set, path_test_set), verbose=2)\n",
      ],
      "metadata": {
        "id": "fmlhcOX19GqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
